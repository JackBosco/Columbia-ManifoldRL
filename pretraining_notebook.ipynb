{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We want to operate a car in the simulated racing environment [Car Racing](https://gymnasium.farama.org/environments/box2d/car_racing/).\n",
    "\n",
    "There are two steps. First is pretraining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space\n",
    "\n",
    "$$ \\mathbb R ^ {3} $$\n",
    "\n",
    "Actions are continuous 3-vector:\n",
    "\n",
    "- 0: steering, -1 is full left, +1 is full right\n",
    "\n",
    "- 1: gas\n",
    "\n",
    "- 2: braking\n",
    "\n",
    "### Observation Space\n",
    "\n",
    "$$(256)^{96 \\times 96}$$\n",
    "\n",
    "A top-down 96x96 RGB image of the car and race track\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We have over 2,000 screen captures from the Car Racing simulator.\n",
    "\n",
    "Each is the same 96x96 colored resolution as the model input.\n",
    "They also have labels: left, right or straight for the direction of the car.\n",
    "For example, see 3 samples:\n",
    "\n",
    "LEFT: ![LEFT](./images/frame-1002-left.png)\n",
    "STRAIGHT: ![STRAIGHT](./images/frame-100-straight.png)\n",
    "RIGHT: ![RIGHT](./images/frame-207-right.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "We can cut off the top part (above the toolbar) and flip that horizontally. This is valid since the car always points north. It effectively doubles the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Lastly we should batch the images and load them randomly for pretraining.\n",
    "\n",
    "They are labelled, but the labels don't matter right now. Later we can use the labels to generate an *average representation* of left, right and stright roads.\n",
    "\n",
    "We can use this for XAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "We use a variational autoencoder to learn low-dimensional representations for the state space.\n",
    "\n",
    "This is pretraining: the objective is to simply reconstruct the original input image after passing through a low-D bottleneck."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

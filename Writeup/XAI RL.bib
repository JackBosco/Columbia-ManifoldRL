
@article{lesort_state_2018,
	title = {State {Representation} {Learning} for {Control}: {An} {Overview}},
	volume = {108},
	issn = {08936080},
	shorttitle = {State {Representation} {Learning} for {Control}},
	url = {http://arxiv.org/abs/1802.04181},
	doi = {10.1016/j.neunet.2018.07.006},
	abstract = {Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. The representation is learned to capture the variation in the environment generated by the agent's actions; this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension characteristic of the representation helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning. This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.},
	urldate = {2025-03-10},
	journal = {Neural Networks},
	author = {Lesort, Timothée and Díaz-Rodríguez, Natalia and Goudou, Jean-François and Filliat, David},
	month = dec,
	year = {2018},
	note = {arXiv:1802.04181 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {379--392},
}

@misc{kalra_rlinspect_2024,
	title = {{RLInspect}: {An} {Interactive} {Visual} {Approach} to {Assess} {Reinforcement} {Learning} {Algorithm}},
	shorttitle = {{RLInspect}},
	url = {http://arxiv.org/abs/2411.08392},
	doi = {10.48550/arXiv.2411.08392},
	abstract = {Reinforcement Learning (RL) is a rapidly growing area of machine learning that finds its application in a broad range of domains, from finance and healthcare to robotics and gaming. Compared to other machine learning techniques, RL agents learn from their own experiences using trial and error, and improve their performance over time. However, assessing RL models can be challenging, which makes it difficult to interpret their behaviour. While reward is a widely used metric to evaluate RL models, it may not always provide an accurate measure of training performance. In some cases, the reward may seem increasing while the model's performance is actually decreasing, leading to misleading conclusions about the effectiveness of the training. To overcome this limitation, we have developed RLInspect - an interactive visual analytic tool, that takes into account different components of the RL model - state, action, agent architecture and reward, and provides a more comprehensive view of the RL training. By using RLInspect, users can gain insights into the model's behaviour, identify issues during training, and potentially correct them effectively, leading to a more robust and reliable RL system.},
	urldate = {2025-03-10},
	publisher = {arXiv},
	author = {Kalra, Geetansh and Singh, Divye and Jose, Justin},
	month = nov,
	year = {2024},
	note = {arXiv:2411.08392 [cs]
version: 1},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{gebauer_pitfall_2021,
	title = {The {Pitfall} of {More} {Powerful} {Autoencoders} in {Lidar}-{Based} {Navigation}},
	url = {http://arxiv.org/abs/2102.02127},
	doi = {10.48550/arXiv.2102.02127},
	abstract = {The benefit of pretrained autoencoders for reinforcement learning in comparison to training on raw observations is already known [1]. In this paper, we address the generation of a compact and information-rich state representation. In particular, we train a variational autoencoder for 2D-lidar scans to use its latent state for reinforcement learning of navigation tasks. To achieve high reconstruction power of our autoencoding pipeline, we propose an - in the context of autoencoding 2D-lidar scans - novel preprocessing into a local binary occupancy image. This has no additional requirements, neither self-localization nor robust mapping, and therefore can be applied in any setting and easily transferred from simulation in real-world. In a second stage, we show the usage of the compact state representation generated by our autoencoding pipeline in a simplistic navigation task and expose the pitfall that increased reconstruction power will always lead to an improved performance. We implemented our approach in python using tensorflow. Our datasets are simulated with pybullet as well as recorded using a slamtec rplidar A3. The experiments show the significantly improved reconstruction capabilities of our approach for 2D-lidar scans w.r.t. the state of the art. However, as we demonstrate in the experiments the impact on reinforcement learning in lidar-based navigation tasks is non-predictable when improving the latent state representation generated by an autoencoding pipeline. This is surprising and needs to be taken into account during the process of optimizing a pretrained autoencoder for reinforcement learning tasks.},
	urldate = {2025-03-11},
	publisher = {arXiv},
	author = {Gebauer, Christopher and Bennewitz, Maren},
	month = mar,
	year = {2021},
	note = {arXiv:2102.02127 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
}

@misc{white_sampling_2016,
	title = {Sampling {Generative} {Networks}},
	url = {http://arxiv.org/abs/1609.04468},
	doi = {10.48550/arXiv.1609.04468},
	abstract = {We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation. Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.},
	urldate = {2025-03-11},
	publisher = {arXiv},
	author = {White, Tom},
	month = dec,
	year = {2016},
	note = {arXiv:1609.04468 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{kingma_auto-encoding_2013,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	doi = {10.48550/arXiv.1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2025-04-29},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2013},
	note = {arXiv:1312.6114 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	doi = {10.48550/arXiv.1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2025-04-29},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv:1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{klimov_gymnasium_nodate,
	title = {Gymnasium {Documentation}},
	url = {https://gymnasium.farama.org/environments/box2d/car_racing.html},
	abstract = {A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym)},
	language = {en},
	urldate = {2025-04-29},
	journal = {Gymnasium},
	author = {Klimov, Oleg},
}

@misc{torch.utils.data,
	title = {torch.utils.data — {PyTorch} 2.7 documentation},
	url = {https://pytorch.org/docs/stable/data.html},
	urldate = {2025-04-29},
}

@article{kingma_introduction_2019,
	title = {An {Introduction} to {Variational} {Autoencoders}},
	volume = {12},
	issn = {1935-8237, 1935-8245},
	url = {http://arxiv.org/abs/1906.02691},
	doi = {10.1561/2200000056},
	abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
	number = {4},
	urldate = {2025-04-29},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Kingma, Diederik P. and Welling, Max},
	year = {2019},
	note = {arXiv:1906.02691 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {307--392},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2025-04-29},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{shorten_survey_2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	number = {1},
	urldate = {2025-04-29},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	month = jul,
	year = {2019},
	keywords = {Big data, Data Augmentation, Deep Learning, GANs, Image data},
	pages = {60},
}

@article{ha_world_2018,
	title = {World {Models}},
	url = {https://zenodo.org/records/1207631},
	doi = {10.5281/zenodo.1207631},
	abstract = {We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment.


An interactive version of this article is available at worldmodels.github.io.},
	urldate = {2025-04-29},
	author = {Ha, David and Schmidhuber, Jürgen},
	month = mar,
	year = {2018},
}

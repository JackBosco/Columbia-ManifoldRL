\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{mathptmx}
\usepackage{biblatex}
\usepackage{times}       % assumes new font selection scheme installed
\usepackage{amsmath}     % assumes amsmath package installed
\usepackage{amssymb}     % assumes amsmath package installed
\usepackage{graphicx}
\usepackage[font=small]{caption} % set table caption below Table for longer descriptions
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{hhline}
% \usepackage[ruled,noline,noend]{algorithm2e}
% \usepackage[noend]{algpseudocode}

\bibliography{XAI RL}

\usepackage[colorlinks=true, urlcolor=blue]{hyperref}
\geometry{top=0.5in, bottom=0.5in, left=0.5in, right=0.5in}

\newcolumntype{Y}{>{\centering\arraybackslash}X}% new Y, equal sized as X but centered
\renewcommand\tabularxcolumn[1]{m{#1}}% for vertical centering text in X column
\setlength\extrarowheight{1pt}

\begin{document}

\title{\textbf{Reinforcement Learning Project Proposal}}

\author{Joseph (Jack) Bosco \\ jab2516  \and Akshara Pramod \\ ap4613}
\date{Date : 11th March, 2025}

\maketitle 

\begin{center}
    {\large \textbf{A Study on Explainability in RL Models}}
\end{center}

\noindent \textbf{Idea}\\
This project aims to improve explainability in reinforcement learning by incorporating Variational Autoencoders (VAEs) to create meaningful latent representations of the CarRacing-v0 environment. Instead of directly training an RL agent on high-dimensional raw pixel inputs, we propose learning a compressed latent space using a VAE as it would capture essential driving features. The RL model will then learn policies in this reduced representation space, making training more efficient and interpretable. To further enhance explainability, we will apply t-SNE to visualize decision-making in the latent space. We also plan to leverage KL divergence in VAE loss to extract more meaningful and well-formed latent space.\\
\\
\noindent \textbf{Motivation} \\
For AI models to be safely deployed, especially in environments where human safety or well-being is involved, stakeholders must be able to interpret and trust the decisions made by these models. Deep RL models trained on high-dimensional image data often act as black boxes, making it difficult to interpret why certain decisions are made. This lack of transparency limits trust in RL-based autonomous decision-making, particularly in safety-critical domains like self-driving cars.  
\\

\noindent \textbf{Proposal}\\
We aim to follow methods set out in \cite{gebauer_pitfall_2021} using variational autoencoders (VAE) to learn explicit latent space representations for high-dimensional input space.
First we pretrain the autoencoder on a bunch of episodes from an actual human playing the game.
The objective is to reconstruct the game frame-by-frame through a low-dimensional bottleneck. 
After pretraining we append a new neural network to the bottleneck in the architecture which experiences reward from the environment and back-propagates the reward to the encoder.
This will be the RL component.
For explainability we can use VAE to generate interpretable representations from the state space \cite{white_sampling_2016}.
More interestingly, we can generate novel images using the geometric average latent space coordinate of a certain feature. 
This latent space arithmetic is known to reveal model biases and is a useful tool for interpreting how the RL agent responds to certain scenarios.
\\\\
\noindent \textbf{Dataset: \href{https://gymnasium.farama.org/environments/box2d/car_racing/}{CarRacing-v2 (OpenAI Gymnasium Box2D)}}\\
The CarRacing-v2 dataset is a continuous high-dimensional control environment from OpenAI Gymnasiumâ€™s Box2D suite. It involves controlling a car on procedurally generated racetracks, requiring precise navigation and long-term strategy to optimize lap times. The state space consists of 96x96 RGB images, making it a computer vision-based RL problem. The agent controls acceleration, braking, and steering in a continuous action space. The reward is equal to 1000-the time it takes to complete a lap.

\section{Methods}

\subsection{Data Collection and Preprocessing}
We collected over 2\,000 top-down RGB frames (96 $\times$ 96 $\times$ 3) from human-driven episodes of CarRacing-v2.  To increase data diversity, we crop off the static toolbar (pixels 0-83) and apply horizontal flips only above that line, effectively doubling samples for left- and right-turn frames \cite{ioffe_batch_2015, klimov_gymnasium_nodate}.  All images are saved as PNG and converted to floating-point tensors in [0,1].

\subsection{Dataset Splitting}
We treat the full set of augmented frames as a single map-style \texttt{Dataset} and split it randomly into 80\% train, 10\% validation, and 10\% test subsets using \texttt{torch.utils.data.random\_split} \cite{torch.utils.data}. This ensures non-overlapping, stratified usage for pretraining and held-out evaluation.

\subsection{Variational Autoencoder Pretraining}
Our pretraining objective is to learn a compact latent representation of frames by reconstructing inputs through a low-dimensional bottleneck (Fig.~\ref{tab:arch_new}).  We employ a Variational Autoencoder (VAE) whose encoder outputs mean and log-variance for a diagonal Gaussian in \(\mathbb{R}^k\) \cite{kingma_auto-encoding_2013}.  The reparameterization trick makes the stochastic sampling differentiable \cite{kingma_auto-encoding_2013}.  Each convolutional layer is followed by Batch Normalization and ReLU activations to stabilize and accelerate training \cite{ioffe_batch_2015}.

The VAE loss is the negative Evidence Lower Bound (ELBO):
\[
\mathcal{L} = \underbrace{\mathbb{E}_{q(z\mid x)}\bigl[-\log p(x\mid z)\bigr]}_{\text{BCE reconstruction}} \;+\; \underbrace{D_{KL}\bigl(q(z\mid x)\,\|\,p(z)\bigr)}_{\text{KL divergence}}.
\]
We compute reconstruction via binary cross-entropy summed over pixels, and the KL term analytically for two Gaussians.

\subsection{Implementation Details}
We implement the VAE in PyTorch1.x, optimize with Adam (learning rate 1e-3, \(\beta_1=0.9,\beta_2=0.999\)), and train for 200 epochs with batch size 64.  Model weights are checkpointed every 20 epochs.  Early validation reconstructions are displayed periodically to monitor overfitting.

\subsection{Rationale for Pretraining}
By learning an unsupervised world model of the CarRacing frames, we extract features that capture essential track geometry and car orientation \cite{ha_world_2018}. These compact latent features greatly reduce the state dimensionality for the downstream RL agent, improving sample efficiency and interpretability \cite{white_sampling_2016}.

\begin{table}
\centering
{\footnotesize
\begin{tabularx}{.95\linewidth}{|Y||Y|}
\hline
\textbf{Encoder} & \textbf{Decoder} \\ \hhline{|=||=|}
\textbf{Input}: $96 \times 96 \times 3$ RGB image & \textbf{Input}: latent sample $\in \mathbb{R}^{k}$ \\ \hhline{|-||-|}
Conv. $32 \times 3 \times 3$, stride 2, ReLU, BN & Dense, 256, ReLU \\ \hhline{|-||-|}
Max pool. $2 \times 2$ & Dense, $3 \times 3 \times 128$, ReLU reshaped \\ \hhline{|-||-|}
Conv. $32 \times 3 \times 3$, stride 2, ReLU, BN & Trans. Conv., $128 \times 3 \times 3$, stride 2, ReLU \\ \hhline{|-||-|}
Conv. $64 \times 3 \times 3$, stride 1, ReLU, BN & Trans. Conv., $64 \times 3 \times 3$, stride 2, ReLU \\ \hhline{|-||-|}
Avg. pool. $2 \times 2$ & Trans. Conv., $32 \times 3 \times 3$, stride 2, ReLU \\ \hhline{|-||-|}
Conv. $128 \times 3 \times 3$, stride 2, ReLU, BN, flatten & Trans. Conv., $32 \times 3 \times 3$, stride 2, ReLU \\ \hhline{|-||-|}
Dense, 256, ReLU & Trans. Conv., $16 \times 3 \times 3$, stride 2, ReLU \\ \hhline{|-||-|}
Dense, $2\text{k}$ & Conv. $3 \times 3 \times 3$, stride 1 \\ \hhline{|-||-|}
\textbf{Output}: Diag. Gaussian & \textbf{Output}: Ind. Bernoulli \\ \hline
\end{tabularx}
}
\caption{Revised network architecture for a 96x96 RGB input.}
\label{tab:arch_new}
\end{table}


\printbibliography

\end{document}

